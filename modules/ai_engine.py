"""
AI Engine Module - Windows Log Analizi iÃ§in Brain SÄ±nÄ±fÄ±
Production-Ready: JSON Ã§Ä±ktÄ± formatÄ± ve type hints ile gÃ¼ncellendi
"""
import ollama
import re
import json
import logging
from typing import Optional, Dict, Any, Tuple
from pydantic import ValidationError

import config
from modules.knowledge_base import get_event_info
from modules.ai_models import AIAnalysisResponse

# Logging yapÄ±landÄ±rmasÄ±
logger = logging.getLogger(__name__)


class Brain:
    """
    Windows gÃ¼venlik loglarÄ±nÄ± analiz eden AI sÄ±nÄ±fÄ±.
    Ollama Ã¼zerinde Ã§alÄ±ÅŸan lokal LLM kullanÄ±r.
    Production-Ready: JSON Ã§Ä±ktÄ± formatÄ± ve type-safe parsing
    """
    
    def __init__(self, model_name: Optional[str] = None) -> None:
        """
        Brain sÄ±nÄ±fÄ±nÄ± baÅŸlatÄ±r.
        
        Args:
            model_name: Ollama model adÄ± (varsayÄ±lan: config.py'den alÄ±nÄ±r)
        """
        self.model_name: str = model_name or config.MODEL_NAME
        
        # JSON Ã§Ä±ktÄ± formatÄ± iÃ§in system prompt
        self.system_prompt: str = """Sen KÄ±demli bir SOC Analistisin (Cyber Security Expert).
Sana verilen Windows Logunu analiz et ve yanÄ±tÄ±nÄ± MUTLAKA ÅŸu JSON formatÄ±nda ver:

{
    "risk_score": "DÃ¼ÅŸÃ¼k" veya "Orta" veya "YÃ¼ksek",
    "user_entity": "Tespit edilen kullanÄ±cÄ± adÄ± veya makine adÄ±",
    "summary": "OlayÄ±n teknik olmayan, net TÃ¼rkÃ§e aÃ§Ä±klamasÄ±",
    "advice": "Bu durumda ne yapÄ±lmalÄ±? Pratik tavsiyeler",
    "event_id_explanation": "Event ID hakkÄ±nda eÄŸitici aÃ§Ä±klama (opsiyonel)"
}

Ã–NEMLÄ°: 
- CevabÄ±n SADECE JSON olmalÄ±, baÅŸka metin olmamalÄ±
- JSON geÃ§erli ve parse edilebilir olmalÄ±
- KÄ±sa, net ve profesyonel ol"""
    
    def extract_event_id(self, log_text: str) -> Optional[str]:
        """
        Log metninden Event ID'yi Ã§Ä±karÄ±r.
        
        Args:
            log_text: Log metni
        
        Returns:
            Event ID (string) veya None
        """
        match = re.search(r'Event ID\s*[:#]?\s*(\d+)', log_text, re.IGNORECASE)
        return match.group(1) if match else None
    
    def analyze(self, log_text: str) -> Tuple[str, str]:
        """
        Windows log metnini analiz eder ve JSON formatÄ±nda yanÄ±t dÃ¶ndÃ¼rÃ¼r.
        Knowledge base'den bilgi Ã§ekerek analiz kalitesini artÄ±rÄ±r (Hibrit RAG).
        
        Args:
            log_text: Analiz edilecek Windows log metni
        
        Returns:
            tuple[str, str]: (markdown_analysis, risk_score) - Dashboard iÃ§in markdown ve risk seviyesi
        """
        try:
            # Log metninden Event ID'yi Ã§Ä±karmaya Ã§alÄ±ÅŸ
            event_id: Optional[str] = self.extract_event_id(log_text)
            
            # Knowledge base'den bilgi Ã§ek (RAG)
            kb_info: Optional[Dict[str, Any]] = None
            if event_id:
                try:
                    kb_info = get_event_info(event_id)
                    if kb_info:
                        logger.info(f"Knowledge base bilgisi bulundu (Event ID: {event_id}, Kaynak: {kb_info.get('source', 'bilinmiyor')})")
                except Exception as e:
                    logger.warning(f"Knowledge base hatasÄ±: {e}")
            
            # System prompt'u hazÄ±rla
            enhanced_prompt = self.system_prompt
            
            # RAG bilgisini prompt'a ekle (eÄŸer varsa) - PROMPT HARDENING
            if kb_info:
                extra_instruction = f"""

[ğŸ›‘ Ã–ZEL TALÄ°MAT - KRÄ°TÄ°K GÃœVENLÄ°K PROTOKOLÃœ]:
Bu olay (ID: {event_id}) iÃ§in tanÄ±mlanmÄ±ÅŸ bir GÃœVENLÄ°K PROTOKOLÃœ var.

JSON Ã§Ä±ktÄ±ndaki "advice" alanÄ±na, aÅŸaÄŸÄ±daki metni KELÄ°MESÄ° KELÄ°MESÄ°NE (Verbatim) yapÄ±ÅŸtÄ±r. Kendin cÃ¼mle kurma.

ZORUNLU METÄ°N: "{kb_info.get('advice', '')}"

AyrÄ±ca "risk_score" alanÄ±na ÅŸunu yaz: "{kb_info.get('risk_level', 'Orta')}"

[Ã–NEMLÄ°]: YukarÄ±daki "ZORUNLU METÄ°N"i deÄŸiÅŸtirme, kopyala-yapÄ±ÅŸtÄ±r yap.
"""
                enhanced_prompt += extra_instruction
            
            # AI'a gÃ¶nder
            logger.debug(f"AI analizi baÅŸlatÄ±lÄ±yor (Event ID: {event_id})")
            response = ollama.chat(
                model=self.model_name,
                messages=[
                    {
                        'role': 'system',
                        'content': enhanced_prompt
                    },
                    {
                        'role': 'user',
                        'content': f"Bu Windows gÃ¼venlik logunu analiz et:\n\n{log_text}"
                    }
                ]
            )
            
            # AI'Ä±n cevabÄ±nÄ± al
            raw_response: str = response['message']['content'].strip()
            
            # JSON parse et
            try:
                # JSON'u temizle (eÄŸer markdown code block iÃ§indeyse)
                json_str = raw_response
                if "```json" in json_str:
                    json_str = json_str.split("```json")[1].split("```")[0].strip()
                elif "```" in json_str:
                    json_str = json_str.split("```")[1].split("```")[0].strip()
                
                # JSON parse et
                json_data = json.loads(json_str)
                
                # Pydantic model ile validate et
                analysis_response = AIAnalysisResponse(**json_data)
                
                logger.info(f"AI analizi baÅŸarÄ±yla parse edildi (Risk: {analysis_response.risk_score})")
                
                # Markdown formatÄ±na Ã§evir ve risk_score ile birlikte dÃ¶ndÃ¼r
                markdown_analysis = analysis_response.to_markdown()
                return markdown_analysis, analysis_response.risk_score
                
            except (json.JSONDecodeError, ValidationError) as e:
                logger.error(f"JSON parse hatasÄ±: {e}, Raw response: {raw_response[:200]}")
                # Fallback: Raw response'u dÃ¶ndÃ¼r
                fallback_markdown = self._create_fallback_response(event_id, raw_response)
                return fallback_markdown, "Orta"
                
        except Exception as e:
            logger.error(f"AI analiz hatasÄ±: {e}", exc_info=True)
            fallback_markdown = self._create_fallback_response(event_id, f"AI HatasÄ±: {str(e)}")
            return fallback_markdown, "Orta"
    
    def _create_fallback_response(self, event_id: Optional[str], error_message: str) -> str:
        """
        Hata durumunda fallback response oluÅŸturur.
        
        Args:
            event_id: Event ID (varsa)
            error_message: Hata mesajÄ±
        
        Returns:
            str: Fallback markdown response
        """
        event_id_str = event_id if event_id else "Bilinmiyor"
        return f"""ğŸ†” Event ID {event_id_str} Nedir?
Bu Event ID, Windows gÃ¼venlik sisteminin kaydettiÄŸi bir olaydÄ±r.

ğŸ•µï¸â€â™‚ï¸ Olay Analizi
KullanÄ±cÄ±: Analiz Edilemedi
Durum: {error_message}
Risk: Orta

ğŸ’¡ Tavsiye
Log mesajÄ±nÄ± manuel olarak kontrol edin veya sistem yÃ¶neticisi ile iletiÅŸime geÃ§in."""
